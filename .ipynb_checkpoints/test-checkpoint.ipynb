{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1060 6GB (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, re, sys, time\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# keras stuff\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras import callbacks\n",
    "\n",
    "# scipy stuff\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import mode\n",
    "\n",
    "# preprocessing stuff\n",
    "from preprocessingTR import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Loaded model in 48.95s\n"
     ]
    }
   ],
   "source": [
    "print('Loading model')\n",
    "t0 = time.time()\n",
    "model = keras.models.load_model('./Models/ConvNetC.h5')\n",
    "t1 = time.time()\n",
    "print('Loaded model in %.2fs' % (t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_lookup = {0: 'other', 1: 'Mukund', 2: 'Frank'}\n",
    "user2netid = {0: 'other', 1:'ms2666', 2: 'fc249'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(xpath='./Data_test/processed/full.pickle'):\n",
    "    return pd.read_pickle(xpath)\n",
    "\n",
    "def scale_data(df, model_dir='./Models/'):\n",
    "    \"\"\"\n",
    "    Scale data\n",
    "    \"\"\"\n",
    "    xTe = df.values\n",
    "    ss = joblib.load(model_dir + 'ss.pkl')\n",
    "    xTe = ss.transform(xTe)\n",
    "\n",
    "    return xTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_dict = generate_udict('./Data_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0]}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user 0, trial 0, 0 remaining\n"
     ]
    }
   ],
   "source": [
    "# preprocess and save training data\n",
    "preprocess_and_save(u_dict, dir_name='./Data_test/processed/', begin_idx=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full.pickle not found... Building now\n",
      "0_Y.npy\n",
      "0_X.csv\n",
      "Loading user 0\n"
     ]
    }
   ],
   "source": [
    "merge_incremental(base='./Data_test/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and split data\n",
    "data = load_data()\n",
    "xTe = scale_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xTe_conv = xTe.reshape(-1, 3, 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(xTe_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frank'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_lookup[mode(preds.round().argmax(axis=1)).mode[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
